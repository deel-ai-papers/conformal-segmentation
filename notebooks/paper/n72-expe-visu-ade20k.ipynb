{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization: CRC\n",
    "\n",
    "Losses:\n",
    "- binary w/ threshold\n",
    "- Miscoverage\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from cose.utils import load_project_paths\n",
    "from app.tools import setup_mmseg_inference\n",
    "from cose.conformal import split_dataset_idxs\n",
    "from mmengine.registry import init_default_scope  # type: ignore\n",
    "\n",
    "init_default_scope(\"mmseg\")\n",
    "\n",
    "\n",
    "# device_str = \"cuda:0\"\n",
    "device_str = \"cuda:1\"\n",
    "# device_str = \"cpu\"\n",
    "device = torch.device(device_str)\n",
    "\n",
    "prj_path = load_project_paths().COSE_PATH\n",
    "\n",
    "# dataset: Literal[\"Cityscapes\", \"ADE20K\", \"LoveDA\"]\n",
    "dataset_name = \"ADE20K\"\n",
    "\n",
    "# loss: Literal[\"binary\", \"miscoverage\"]\n",
    "loss = \"miscoverage\"\n",
    "# loss = \"binary\"\n",
    "\n",
    "# my_alpha = 0.1\n",
    "my_alpha = 0.01\n",
    "\n",
    "if dataset_name == \"ADE20K\" and loss == \"binary\":\n",
    "    if my_alpha == 0.1:\n",
    "        config_json = f\"{prj_path}/experiments/outputs/ADE20K/binary_loss/20240315_23h17m12s_ADE20K__id_102__alpha_0.1__binary_loss.json\"\n",
    "    elif my_alpha == 0.01:\n",
    "        # # mincov: 0.75, alpha=0.01\n",
    "        config_json = f\"{prj_path}/experiments/outputs/ADE20K/binary_loss/20240316_02h39m23s_ADE20K__id_102__alpha_0.01__binary_loss.json\"\n",
    "    else:\n",
    "        raise ValueError(f\"{my_alpha = }\")\n",
    "elif dataset_name == \"ADE20K\" and loss == \"miscoverage\":\n",
    "    if my_alpha == 0.01:\n",
    "        config_json = f\"{prj_path}/experiments/outputs/ADE20K/miscoverage_loss/20240303_02h19m59s_ADE20K__id_102__alpha_0.01__miscoverage_loss.json\"\n",
    "\n",
    "my_config = json.load(open(config_json))\n",
    "n_calib = my_config[\"n_calib\"]\n",
    "print(f\"{my_config['mincov'] = }\")\n",
    "print(my_config.keys())\n",
    "print(f\"{my_config['experiment_id'] = }\")\n",
    "\n",
    "dataset, model, input_paths = setup_mmseg_inference(\n",
    "    device, dataset_name, my_config[\"experiment_id\"], n_calib=n_calib\n",
    ")\n",
    "#\n",
    "_cal_ids, test_ids = split_dataset_idxs(\n",
    "    len_dataset=len(dataset),\n",
    "    n_calib=my_config[\"n_calib\"],\n",
    "    random_seed=my_config[\"experiment_id\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "\n",
    "image_id_ = None\n",
    "\n",
    "show_some_images = False\n",
    "if show_some_images:\n",
    "\n",
    "    for i in range(100, 200, 4):\n",
    "        id1, id2, id3, id4 = (\n",
    "            test_ids[i],\n",
    "            test_ids[i + 1],\n",
    "            test_ids[i + 2],\n",
    "            test_ids[i + 3],\n",
    "        )\n",
    "\n",
    "        # Plot for the first subplot\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(10, 4))\n",
    "        im_path = dataset[id1][\"data_samples\"].img_path\n",
    "        im = mmcv.imread(im_path)\n",
    "        axs[0].imshow(mmcv.bgr2rgb(im))\n",
    "        axs[0].set_title(f\"id: {id1}\")\n",
    "\n",
    "        # Plot for the second subplot\n",
    "        im_path = dataset[id2][\"data_samples\"].img_path\n",
    "        im = mmcv.imread(im_path)\n",
    "        axs[1].imshow(mmcv.bgr2rgb(im))\n",
    "        axs[1].set_title(f\"id: {id2}\")\n",
    "\n",
    "        im_path = dataset[id3][\"data_samples\"].img_path\n",
    "        im = mmcv.imread(im_path)\n",
    "        # Plot for the third subplot\n",
    "        axs[2].imshow(mmcv.bgr2rgb(im))\n",
    "        axs[2].set_title(f\"id: {id3}\")\n",
    "\n",
    "        im_path = dataset[id4][\"data_samples\"].img_path\n",
    "        im = mmcv.imread(im_path)\n",
    "        # Plot for the third subplot\n",
    "        axs[3].imshow(mmcv.bgr2rgb(im))\n",
    "        axs[3].set_title(f\"id: {id4}\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == \"ADE20K\":\n",
    "    # image_id_ = 3\n",
    "    # image_id_ = 37\n",
    "    # image_id_ = 44\n",
    "    # image_id_ = 184\n",
    "    # image_id_ = 203\n",
    "    # image_id_ = 308\n",
    "    image_id_ = 312\n",
    "    # image_id_ = 314\n",
    "\n",
    "    im_path = dataset[image_id_][\"data_samples\"].img_path\n",
    "    print(f\"[LUCA dbg] {im_path = }\")\n",
    "    im = mmcv.imread(im_path)\n",
    "    plt.imshow(mmcv.bgr2rgb(im))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.tools import parse_arguments, setup_gpu, setup_mmseg_inference\n",
    "from app.tools import heatmap_from_multimaks, segmask_from_softmax\n",
    "from cose.conformal import lac_multimask, PredictionHandler\n",
    "from PIL import Image\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "def plot_heatmap_from_input_img_path(\n",
    "    input_img_path: str,\n",
    "    expe_config,\n",
    "    normalize_by_total_number_of_classes,\n",
    "):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    threshold = expe_config[\"optimal_lambda\"]\n",
    "\n",
    "    dataset, model, _ = setup_mmseg_inference(\n",
    "        torch_device=device,\n",
    "        use_case=expe_config[\"dataset\"],\n",
    "        random_seed=expe_config[\"experiment_id\"],\n",
    "        n_calib=expe_config[\"n_calib\"],\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictor = PredictionHandler(model[\"model\"].mmseg_model)\n",
    "\n",
    "        softmax_prediction = predictor.predict(input_img_path)\n",
    "        segmask = segmask_from_softmax(softmax_prediction).cpu().numpy()\n",
    "\n",
    "        cmap = mpl.colormaps[\"tab20\"]\n",
    "        segmask = Image.fromarray(cmap(segmask / segmask.max(), bytes=True))  # * 255)\n",
    "\n",
    "        figure_size = (21, 5)\n",
    "        fig, axs = plt.subplots(1, 3, figsize=figure_size, dpi=200)\n",
    "\n",
    "        _input = mmcv.imread(input_img_path)\n",
    "        ax1 = plt.subplot(1, 3, 1)\n",
    "        ax1.set_title(\"Input image\")\n",
    "        ax1.imshow(mmcv.bgr2rgb(_input))\n",
    "\n",
    "        ax2 = plt.subplot(1, 3, 2)\n",
    "        ax2.set_title(\"Segmentation mask\")\n",
    "        ax2.imshow(segmask, alpha=0.5, cmap=cmap)\n",
    "\n",
    "        multimask = lac_multimask(\n",
    "            threshold=threshold,\n",
    "            predicted_softmax=softmax_prediction,\n",
    "            n_labels=dataset.n_classes,\n",
    "        )\n",
    "\n",
    "        cmap = mpl.colormaps[\"turbo\"]\n",
    "        _map = multimask.sum(dim=0).cpu().numpy()\n",
    "\n",
    "        if normalize_by_total_number_of_classes:\n",
    "            vmax = dataset.n_classes\n",
    "        else:\n",
    "            vmax = multimask.sum(dim=0).max().cpu().numpy()\n",
    "\n",
    "        ax3 = plt.subplot(1, 3, 3)\n",
    "        ax3.set_title(\"Uncertainty heatmap\")\n",
    "        im = ax3.imshow(_map, cmap=cmap, aspect=\"equal\", vmax=vmax)\n",
    "\n",
    "        fig.colorbar(im, ax=ax3, label=\"Number of classes per pixel\", pad=0.05)\n",
    "        plt.rcParams.update({\"font.size\": 10})\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "plot_heatmap_from_input_img_path(\n",
    "    input_img_path=im_path,\n",
    "    expe_config=my_config,\n",
    "    normalize_by_total_number_of_classes=True,\n",
    "    # normalize_by_total_number_of_classes=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding: visualize how $\\lambda$ determines the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "\n",
    "def plot_threshold_heatmap_from_input_img_path(\n",
    "    input_img_path: str,\n",
    "    expe_config,\n",
    "    normalize_by_total_number_of_classes,\n",
    "    n_classes: int,\n",
    "    lbd: Sequence[float],\n",
    "):\n",
    "    dataset, model, _ = setup_mmseg_inference(\n",
    "        torch_device=device,\n",
    "        use_case=expe_config[\"dataset\"],\n",
    "        random_seed=expe_config[\"experiment_id\"],\n",
    "        n_calib=expe_config[\"n_calib\"],\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        predictor = PredictionHandler(model[\"model\"].mmseg_model)\n",
    "        softmax_prediction = predictor.predict(input_img_path)\n",
    "\n",
    "        segmask = segmask_from_softmax(softmax_prediction).cpu().numpy()\n",
    "        _input = mmcv.imread(input_img_path)\n",
    "        plt.imshow(mmcv.bgr2rgb(_input))\n",
    "        plt.imshow(segmask, cmap=\"tab20\", alpha=0.5)\n",
    "        plt.show()\n",
    "\n",
    "        figure_size = (22, 10)\n",
    "        fig, axs = plt.subplots(1, len(lbd), figsize=figure_size, dpi=300)\n",
    "        for i, lb in enumerate(lbd):\n",
    "\n",
    "            multimask = lac_multimask(\n",
    "                threshold=lb,\n",
    "                predicted_softmax=softmax_prediction,\n",
    "                n_labels=dataset.n_classes,\n",
    "            )\n",
    "            heatmap = multimask.sum(dim=0).cpu().numpy()\n",
    "            if normalize_by_total_number_of_classes:\n",
    "                vmax = n_classes\n",
    "            else:\n",
    "                vmax = heatmap.max().item()\n",
    "\n",
    "            cmap = mpl.colormaps[\"turbo\"]\n",
    "\n",
    "            ax = axs[i]\n",
    "            hm = ax.imshow(\n",
    "                heatmap,\n",
    "                cmap=cmap,\n",
    "                vmax=vmax,\n",
    "            )\n",
    "\n",
    "            if i > 0:\n",
    "                # plt.xticks([])\n",
    "                ax.set_yticks([])\n",
    "\n",
    "            ax.set_title(f\"$\\lambda = $ {lb}\")\n",
    "\n",
    "            # plt.colorbar(shrink=0.5, aspect=\"equal\")\n",
    "            # plt.subplots_adjust(hspace=0)\n",
    "            # plt.subplots_adjust(wspace=0, hspace=0)\n",
    "            plt.colorbar(\n",
    "                hm, ax=ax, label=\"Number of classes per pixel\", pad=0.05, shrink=0.25\n",
    "            )\n",
    "\n",
    "        plt.rcParams.update({\"font.size\": 10})\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "plot_threshold_heatmap_from_input_img_path(\n",
    "    input_img_path=im_path,\n",
    "    expe_config=my_config,\n",
    "    normalize_by_total_number_of_classes=False,  # True,\n",
    "    # normalize_by_total_number_of_classes=True,\n",
    "    lbd=[0.99, 0.999, 0.999999, 0.99999999, 0.9999999999],\n",
    "    n_classes=dataset.n_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
