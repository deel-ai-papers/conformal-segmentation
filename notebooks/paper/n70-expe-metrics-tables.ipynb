{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization: CRC\n",
    "\n",
    "Losses:\n",
    "- binary w/ threshold\n",
    "- Miscoverage\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from typing import Literal\n",
    "from cose.utils import load_project_paths\n",
    "\n",
    "device_str = \"cuda:0\"\n",
    "# device_str = \"cuda:1\"\n",
    "# device_str = \"cpu\"\n",
    "device = torch.device(device_str)\n",
    "\n",
    "prj_path = load_project_paths().COSE_PATH\n",
    "\n",
    "# dataset: Literal[\"Cityscapes\", \"ADE20K\", \"LoveDA\"]\n",
    "\n",
    "# dataset = \"Cityscapes\"\n",
    "# dataset = \"ADE20K\"\n",
    "dataset = \"LoveDA\"\n",
    "do_loveda_mincv_09 = True\n",
    "\n",
    "datasets = [\"Cityscapes\", \"ADE20K\", \"LoveDA\"]\n",
    "\n",
    "\n",
    "# loss: Literal[\"binary\", \"miscoverage\"]\n",
    "# loss = \"binary\"\n",
    "loss = \"miscoverage\"\n",
    "losses = [\"binary\", \"miscoverage\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test results: load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(clbd.columns) = {'res_path', 'cal_id', 'optimal_lambda', 'loss_function', 'alpha', 'n_calib', 'mincov', 'config_id', 'random_seed', 'early_stopped', 'dataset', 'expe_name'}\n",
      "set(resu.columns) = {'optimal_lambda', 'loss_function', 'empirical_risk', 'activations', 'alpha', 'id_path', 'mincov', 'config_id', 'expe_setup', 'empirical_coverage_ratio', 'random_seed'}\n",
      "[LUCA dbg] clbd.config_id.unique() = array(['0.2_False_101', '0.1_False_101', '0.05_False_101',\n",
      "       '0.01_False_101', '0.005_False_101', '0.2_False_102',\n",
      "       '0.1_False_102', '0.05_False_102', '0.01_False_102',\n",
      "       '0.005_False_102', '0.2_False_103', '0.1_False_103',\n",
      "       '0.05_False_103', '0.01_False_103', '0.005_False_103',\n",
      "       '0.2_False_104', '0.1_False_104', '0.05_False_104',\n",
      "       '0.01_False_104', '0.005_False_104', '0.2_False_105',\n",
      "       '0.1_False_105', '0.05_False_105', '0.01_False_105',\n",
      "       '0.005_False_105', '0.2_False_106', '0.1_False_106',\n",
      "       '0.05_False_106', '0.01_False_106', '0.005_False_106',\n",
      "       '0.2_False_107', '0.1_False_107', '0.05_False_107',\n",
      "       '0.01_False_107', '0.005_False_107', '0.2_False_108',\n",
      "       '0.1_False_108', '0.05_False_108', '0.01_False_108',\n",
      "       '0.005_False_108', '0.2_False_109', '0.1_False_109',\n",
      "       '0.05_False_109', '0.01_False_109', '0.005_False_109',\n",
      "       '0.2_False_110', '0.1_False_110', '0.05_False_110',\n",
      "       '0.01_False_110', '0.005_False_110'], dtype=object)\n",
      "[LUCA dbg] resu.config_id.unique() = array(['0.2_False_101', '0.1_False_101', '0.05_False_101',\n",
      "       '0.01_False_101', '0.005_False_101', '0.2_False_102',\n",
      "       '0.1_False_102', '0.05_False_102', '0.01_False_102',\n",
      "       '0.005_False_102', '0.2_False_103', '0.1_False_103',\n",
      "       '0.05_False_103', '0.01_False_103', '0.005_False_103',\n",
      "       '0.2_False_104', '0.1_False_104', '0.05_False_104',\n",
      "       '0.01_False_104', '0.005_False_104', '0.2_False_105',\n",
      "       '0.1_False_105', '0.05_False_105', '0.01_False_105',\n",
      "       '0.005_False_105', '0.2_False_106', '0.1_False_106',\n",
      "       '0.05_False_106', '0.01_False_106', '0.005_False_106',\n",
      "       '0.2_False_107', '0.1_False_107', '0.05_False_107',\n",
      "       '0.01_False_107', '0.005_False_107', '0.2_False_108',\n",
      "       '0.1_False_108', '0.05_False_108', '0.01_False_108',\n",
      "       '0.005_False_108'], dtype=object)\n",
      " --- difference:\n",
      "{'0.01_False_109', '0.05_False_110', '0.2_False_109', '0.005_False_109', '0.1_False_109', '0.2_False_110', '0.05_False_109', '0.005_False_110', '0.01_False_110', '0.1_False_110'}\n"
     ]
    }
   ],
   "source": [
    "## get optimal lambdas from calibration output (csv format)\n",
    "clbd_csv = f\"{prj_path}/experiments/outputs/processed_lambdas/crc_{loss}_{dataset}_optimized_lambdas.csv\"\n",
    "resu_csv = f\"{prj_path}/experiments/metrics/{dataset}/{dataset}_{loss}_loss.csv\"\n",
    "\n",
    "\n",
    "# loveda for mincov 0.9\n",
    "if do_loveda_mincv_09 and dataset == \"LoveDA\" and loss == \"binary\":\n",
    "    clbd_csv = f\"{prj_path}/experiments/outputs/processed_lambdas/crc_binary_LoveDA_optimized_lambdas_cov_0.9.csv\"\n",
    "    resu_csv = f\"{prj_path}/experiments/metrics/{dataset}/{dataset}_{loss}_loss_0.9.csv\"\n",
    "\n",
    "\n",
    "clbd = pd.read_csv(clbd_csv)\n",
    "\n",
    "clbd[\"mincov\"] = clbd[\"mincov\"].fillna(False)\n",
    "\n",
    "\n",
    "clbd[\"config_id\"] = (\n",
    "    clbd[\"alpha\"].astype(str)\n",
    "    + \"_\"\n",
    "    + clbd[\"mincov\"].astype(str)\n",
    "    + \"_\"\n",
    "    + clbd[\"random_seed\"].astype(str)\n",
    ")\n",
    "print(f\"{set(clbd.columns) = }\")\n",
    "\n",
    "\n",
    "keep_columns = tuple(range(101, 110 + 1))  # , 103)\n",
    "\n",
    "clbd.drop(clbd[~clbd.random_seed.isin(keep_columns)].index, inplace=True)\n",
    "\n",
    "\n",
    "resu = pd.read_csv(resu_csv, index_col=0)\n",
    "resu.drop(resu[~resu.random_seed.isin(keep_columns)].index, inplace=True)\n",
    "\n",
    "resu[\"mincov\"] = resu[\"mincov\"].fillna(False)\n",
    "\n",
    "resu[\"expe_setup\"] = resu[\"alpha\"].astype(str) + \"_\" + resu[\"mincov\"].astype(str)\n",
    "\n",
    "resu[\"config_id\"] = (\n",
    "    resu[\"alpha\"].astype(str)\n",
    "    + \"_\"\n",
    "    + resu[\"mincov\"].astype(str)\n",
    "    + \"_\"\n",
    "    + resu[\"random_seed\"].astype(str)\n",
    ")\n",
    "print(f\"{set(resu.columns) = }\")\n",
    "\n",
    "## Link optimized_lambda to expe in resu_csv\n",
    "print(f\"[LUCA dbg] {clbd.config_id.unique() = }\")\n",
    "print(f\"[LUCA dbg] {resu.config_id.unique() = }\")\n",
    "\n",
    "print(\" --- difference:\")\n",
    "print(set(clbd.config_id.unique()).difference(set(resu.config_id.unique())))\n",
    "\n",
    "# assert (\n",
    "# (set(clbd.config_id.unique()) == set(resu.config_id.unique()))\n",
    "# and (len(clbd) == len(resu))\n",
    "# ) == True, f\"Error: configs in clbd and resu are different: {set(clbd.config_id.unique()).intersection(set(resu.config_id.unique()))}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         config_id dataset  random_seed  alpha  optimal_lambda  mincov  \\\n",
      "0    0.2_False_101  LoveDA          101  0.200        0.973163   False   \n",
      "1    0.1_False_101  LoveDA          101  0.100        0.998640   False   \n",
      "2   0.05_False_101  LoveDA          101  0.050        0.999562   False   \n",
      "3   0.01_False_101  LoveDA          101  0.010        0.999916   False   \n",
      "4  0.005_False_101  LoveDA          101  0.005        0.999966   False   \n",
      "\n",
      "      loss_function  empirical_risk  activations  empirical_coverage_ratio  \\\n",
      "0  miscoverage_loss        0.198286     1.388994                  0.801714   \n",
      "1  miscoverage_loss        0.099392     2.650068                  0.900608   \n",
      "2  miscoverage_loss        0.048548     4.069606                  0.951452   \n",
      "3  miscoverage_loss        0.007724     6.350654                  0.992276   \n",
      "4  miscoverage_loss        0.002503     6.796717                  0.997497   \n",
      "\n",
      "    expe_setup  \n",
      "0    0.2_False  \n",
      "1    0.1_False  \n",
      "2   0.05_False  \n",
      "3   0.01_False  \n",
      "4  0.005_False  \n"
     ]
    }
   ],
   "source": [
    "# merged_df = pd.merge(clbd[[\"config_id\", \"optimal_lambda\"]], resu, on=\"config_id\")\n",
    "merged_df = pd.merge(clbd[[\"config_id\", \"dataset\"]], resu, on=\"config_id\")\n",
    "merged_df.drop(columns=[\"id_path\"], inplace=True)\n",
    "\n",
    "if dataset == \"ADE20K\" and loss == \"binary\":\n",
    "    # 0.5: one run by mistake, no std dev, useless config\n",
    "    merged_df = merged_df[merged_df[\"mincov\"] != 0.5]\n",
    "    # trivial result: lbd = 1.0 (model not good enough to attain non-trivial value (lbd ~ 1.0, heatmap all red))\n",
    "    merged_df = merged_df[merged_df[\"expe_setup\"] != \"0.01_0.9\"]\n",
    "\n",
    "\n",
    "assert not merged_df.isnull().any().any(), \"Error: NaN values found in merged dataframe\"\n",
    "\n",
    "merged_df.groupby([\"alpha\", \"mincov\"]).size().reset_index().rename(columns={0: \"count\"})\n",
    "\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- conf:\t risk_avg +/- (std), covratio_avg +/- (std)\n",
      "empirical_risk              0.01262\n",
      "empirical_coverage_ratio    0.01262\n",
      "dtype: float64\n",
      " --- 0.2_False:\t 0.199 +/- 0.013,\t 0.801 +/- 0.013\n",
      "empirical_risk              0.009427\n",
      "empirical_coverage_ratio    0.009427\n",
      "dtype: float64\n",
      " --- 0.1_False:\t 0.100 +/- 0.009,\t 0.900 +/- 0.009\n",
      "empirical_risk              0.005494\n",
      "empirical_coverage_ratio    0.005494\n",
      "dtype: float64\n",
      " --- 0.05_False:\t 0.049 +/- 0.005,\t 0.951 +/- 0.005\n",
      "empirical_risk              0.000835\n",
      "empirical_coverage_ratio    0.000835\n",
      "dtype: float64\n",
      " --- 0.01_False:\t 0.008 +/- 0.001,\t 0.992 +/- 0.001\n",
      "empirical_risk              0.000252\n",
      "empirical_coverage_ratio    0.000252\n",
      "dtype: float64\n",
      " --- 0.005_False:\t 0.003 +/- 0.000,\t 0.997 +/- 0.000\n"
     ]
    }
   ],
   "source": [
    "colnames_avg_resu = [\n",
    "    \"expesetup\",\n",
    "    \"alpha\",\n",
    "    \"mincov\",\n",
    "    \"riskavg\",\n",
    "    \"riskstd\",\n",
    "    \"activations\",\n",
    "    # \"lbd_avg\",\n",
    "    # \"lbd_std\",\n",
    "    # \"covratio_avg\",\n",
    "    # \"covratio_std\",\n",
    "]\n",
    "avg_resu = []\n",
    "\n",
    "print(\n",
    "    f\" --- conf:\\t risk_avg +/- (std), covratio_avg +/- (std)\"  # ====== lbd_avg +/- (lbd_std)\"\n",
    ")\n",
    "\n",
    "for conf in merged_df[\"expe_setup\"].unique():\n",
    "    subset = merged_df[merged_df[\"expe_setup\"] == conf]\n",
    "    # print(f\"{subset = }\")\n",
    "\n",
    "    assert len(subset[\"alpha\"].unique()) == 1, \"Error: more than one alpha in subset\"\n",
    "    assert len(subset[\"mincov\"].unique()) == 1, \"Error: more than one alpha in subset\"\n",
    "\n",
    "    alpha = subset[\"alpha\"].unique()[0]\n",
    "    activations = subset[\"activations\"].unique()[0]\n",
    "    mincov = subset[\"mincov\"].unique()[0]\n",
    "\n",
    "    risk_avg, covratio_avg = subset[\n",
    "        [\"empirical_risk\", \"empirical_coverage_ratio\"]\n",
    "    ].mean()\n",
    "    risk_std, covratio_std = subset[\n",
    "        [\"empirical_risk\", \"empirical_coverage_ratio\"]\n",
    "    ].std()\n",
    "\n",
    "    print(subset[[\"empirical_risk\", \"empirical_coverage_ratio\"]].std())\n",
    "\n",
    "    print(\n",
    "        f\" --- {conf}:\\t {risk_avg:.3f} +/- {risk_std:.3f},\\t {covratio_avg:.3f} +/- {covratio_std:.3f}\"\n",
    "    )\n",
    "\n",
    "    avg_resu.append(\n",
    "        [\n",
    "            conf,\n",
    "            alpha,\n",
    "            mincov,\n",
    "            risk_avg,\n",
    "            risk_std,\n",
    "            activations,\n",
    "            # lbd_avg,\n",
    "            # lbd_std,\n",
    "            # covratio_avg,\n",
    "            # covratio_std,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "avg_resu = pd.DataFrame(avg_resu, columns=colnames_avg_resu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset = 'LoveDA'\n",
      "loss = 'miscoverage'\n",
      "     expesetup  alpha   riskavg   riskstd  activations\n",
      "0    0.2_False  0.200  0.198736  0.012620     1.388994\n",
      "1    0.1_False  0.100  0.100274  0.009427     2.650068\n",
      "2   0.05_False  0.050  0.048787  0.005494     4.069606\n",
      "3   0.01_False  0.010  0.007777  0.000835     6.350654\n",
      "4  0.005_False  0.005  0.002642  0.000252     6.796717\n",
      "\n",
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "expesetup & alpha & riskavg & riskstd & activations \\\\\n",
      "\\midrule\n",
      "0.2_False & 0.200000 & 0.198736 & 0.012620 & 1.388994 \\\\\n",
      "0.1_False & 0.100000 & 0.100274 & 0.009427 & 2.650068 \\\\\n",
      "0.05_False & 0.050000 & 0.048787 & 0.005494 & 4.069606 \\\\\n",
      "0.01_False & 0.010000 & 0.007777 & 0.000835 & 6.350654 \\\\\n",
      "0.005_False & 0.005000 & 0.002642 & 0.000252 & 6.796717 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_metrics = avg_resu[avg_resu[\"mincov\"] != 1.0]\n",
    "avg_metrics.drop(columns=[\"mincov\"], inplace=True)\n",
    "\n",
    "print(f\"{dataset = }\")\n",
    "print(f\"{loss = }\")\n",
    "\n",
    "print(avg_metrics)\n",
    "print()\n",
    "\n",
    "## generate latex table line\n",
    "print(avg_metrics.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
